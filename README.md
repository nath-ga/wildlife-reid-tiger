# ğŸ… wildlife-reid-tiger â€“ ML-Projekt zur visuellen Wiedererkennung von Wildtieren

## Ziel des Projekts

Dieses Projekt entwickelt ein Machine-Learning-Modell zur visuellen Wiedererkennung einzelner Tiere â€“ mit Fokus auf Tiger. Ziel ist es, anhand von Kamerafallen-Bildern zu erkennen, ob dasselbe Tier mehrfach erscheint â€“ trotz unterschiedlicher Perspektiven, LichtverhÃ¤ltnisse oder KÃ¶rperhaltungen.

Solche Re-Identification-Modelle werden bereits in der Wildtierforschung eingesetzt, um z.â€¯B. PopulationsgrÃ¶ÃŸen besser zu erfassen oder Bewegungsmuster zu analysieren.

## Motivation

- **Ã–kologisch relevant**: UnterstÃ¼tzt Forschung zum Artenschutz
- **Technisch spannend**: Anwendung von Deep Learning mit Siamese-Architektur
- **Portfolio-wirksam**: Kombination aus Computer Vision, Re-ID und DatenverstÃ¤ndnis

## Geplante Schritte

1. **Projektplanung**
   - Zielsetzung und Recherche zu Re-ID im Kontext Wildtiere
      Ziel dieses Projekts ist es, ein Machine-Learning-Modell zu entwickeln, das individuelle afrikanische Leoparden anhand von Kamerafallen-Bildern wiedererkennt.  
      Die Herausforderung besteht darin, trotz unterschiedlicher Blickwinkel, LichtverhÃ¤ltnisse und Posen das gleiche Tier zuverlÃ¤ssig zu identifizieren.  
      Der Datensatz â€Leopard ID 2022â€œ liefert dafÃ¼r echte Tier-IDs, Bounding Boxes und zusÃ¤tzliche Informationen wie Blickrichtung und Zeitstempel.  
      Das Projekt soll die visuelle Wiedererkennung (Re-Identification) durch ein Siamese- oder Triplet-Netzwerk ermÃ¶glichen und die QualitÃ¤t der Zuordnung mithilfe von geeigneten Metriken evaluieren.
   - Auswahl geeigneter Ã¶ffentlich zugÃ¤nglicher DatensÃ¤tze:
     - **Verglichen**: Desert Lion, WCS Camera Traps, Leopard ID 2022
     - **Entschieden**: Leopard ID 2022, da echte Tier-IDs, Bounding Boxes, Blickrichtung, Zeitinfos enthalten sind â†’ optimal fÃ¼r Re-Identification
      Datensatz: Botswana Predator Conservation Trust (2022). Panthera pardus CSV-Export. Abgerufen aus African Carnivore Wildbook vom 28.04.2022.
     - Erste Analyse der Metadaten ergab, dass nur 69 Bilder eine eindeutige Zuordnung zu genau einer Individuen-ID enthalten.  
      Um die KomplexitÃ¤t niedrig zu halten und einen realistischen Startpunkt zu schaffen, wird das initiale Modell auf genau diesen 69 Bildern aufgebaut.  
      Die restlichen Annotationen mit Mehrfachzuordnungen bleiben vorerst ungenutzt, kÃ¶nnten aber in einem zweiten Schritt eingebunden werden.

      Die ursprÃ¼nglich gewÃ¤hlten 69 DatensÃ¤tze enthielten jeweils nur eine eindeutige Individuen-ID, aber kein Tier kam mehrfach vor â€“ daher war keine Paarbildung mÃ¶glich.
      Um ein echtes Trainingsset zu erzeugen, habe ich das Filterkriterium erweitert:
      Alle Annotationen mit mindestens einer individual_id wurden zugelassen, und wenn mehrere IDs enthalten waren, habe ich einfach die erste ID verwendet.
      So konnte ich 6.825 Bilder nutzen und daraus Ã¼ber 471.000 positive sowie 471.000 negative Bildpaare generieren â€“ eine gute Grundlage fÃ¼r das Training eines Re-ID-Modells.

   - Definition der Erfolgskriterien:
      Ich verwende Top-1 Accuracy als Hauptmetrik: Das Modell soll das richtige Tierbild an erster Stelle erkennen.
      WÃ¤hrend des Trainings verwende ich auÃŸerdem die Cosine Similarity, um zu prÃ¼fen, wie Ã¤hnlich zwei Bilder sind.
      Optional kÃ¶nnte ich spÃ¤ter noch Top-5 Accuracy oder mean Average Precision (mAP) nutzen, wenn das Modell stabil lÃ¤uft.


2. **Datenvorbereitung**
   - Strukturieren und ggf. Zuschneiden der Bilder
   - Kategorisierung nach Tier-ID
   - Sicherstellung einheitlicher GrÃ¶ÃŸen, Formate und Helligkeit

3. **Modellaufbau**
   - Kleines Siamese-Netzwerk in PyTorch erstellt
   - Arbeitet mit Graustufenbildern (1 Kanal, 100Ã—100 Pixel)
   - Besteht aus gemeinsamem CNN + FC-Layer â†’ 32-dimensionale Embeddings
   - Funktioniert mit `PairDataset` und gibt zwei Embeddings zurÃ¼ck
   - Erste Tests mit Zufallsbildern erfolgreich durchgefÃ¼hrt
   - Modell ist einsatzbereit fÃ¼r Training mit echten Paaren


4. **Training und Evaluation**
     - DurchfÃ¼hrung des Trainings mit einem Teilset (1000 Paaren) zur Dokumentation im Portfolio.
     - Lernrate: 0.001, Batch Size: 8, Epochs: 10
     - Verlustfunktion: Contrastive Loss
     - Ergebnis (Durchschnittlicher Loss):
       
       | Epoch | Loss |
       |-------|------|
       | 1     | 0.3543 |
       | 2     | 0.3029 |
       | 3     | 0.3025 |
       | 4     | 0.2818 |
       | 5     | 0.2817 |
       | 6     | 0.2689 |
       | 7     | 0.2652 |
       | 8     | 0.2641 |
       | 9     | 0.2494 |
       | 10    | 0.2547 |

     - Das Modell wurde gespeichert unter: `models/siamese_20250617-1348.pt`
     - Aufgrund begrenzter Rechenleistung wurde bewusst nur ein Teilset verwendet. Ziel war ein demonstrierbares Ergebnis mit dokumentiertem Trainingsverlauf.

     - Beispielpaare siehe PrÃ¤sentation.

     Die Cosine Distance wurde als MaÃŸ fÃ¼r visuelle Ã„hnlichkeit berechnet.

5. **Dokumentation & Reflexion**

   - Das Modell zeigt bei kleinem Trainingsumfang bereits ein erkennbares Lernverhalten. Die Cosine-Distanzen unterscheiden zuverlÃ¤ssig Ã¤hnliche und unÃ¤hnliche Bildpaare.
   - Der Verlust (Contrastive Loss) sank im Verlauf der 10 Epochen kontinuierlich, was auf eine gute Konvergenz hindeutet.
   - EinschrÃ¤nkungen: Training wurde bewusst auf 1000 Paare begrenzt, um Speicher- und Rechenzeit zu schonen. Dies erlaubt keine Aussagen Ã¼ber Generalisierbarkeit.
   - FÃ¼r den Demonstrationszweck im Portfolio ist das Projekt erfolgreich abgeschlossen.
   - **VorschlÃ¤ge zur Weiterentwicklung:**
     - Training auf dem vollstÃ¤ndigen Datensatz (471k Paarungen) zur Bewertung echter Top-1-Genauigkeit
     - Einbindung weiterer Tierarten zur Erprobung der Generalisierbarkeit
     - Aufbau einer Web-Demo mit Upload-Funktion (z.â€¯B. mit Streamlit), um Ã„hnlichkeitsvergleiche live zu testen

## Technologien & Tools

- Python 3.10+
- PyTorch â€“ fÃ¼r Modellarchitektur und Training
- torchvision â€“ fÃ¼r Datenvorverarbeitung und Transformationspipelines
- Matplotlib â€“ zur Visualisierung von Bildpaaren und Ã„hnlichkeitswerten
- Pandas â€“ zur Handhabung des Pair-Datensatzes
- Visual Studio Code â€“ als Entwicklungsumgebung

## Projektstruktur (geplant)

<p>
```plaintext
wildlife-reid-tiger/
â”œâ”€â”€ data/            # Rohdaten und bearbeitete Bilder (nicht im Repo)
â”œâ”€â”€ models/          # Trainierte Modelle (ignored)
â”œâ”€â”€ src/             # Trainingslogik, Netzarchitekturen, Hilfsfunktionen
â”œâ”€â”€ outputs/         # Visualisierungen fÃ¼r PrÃ¤sentation (optional)
â”œâ”€â”€ README.md        # Projektdokumentation
â”œâ”€â”€ requirements.txt # Python-AbhÃ¤ngigkeiten
â””â”€â”€ .gitignore       # Ausschlussregeln fÃ¼r sensible/groÃŸe Dateien
</p>

## Projekt-PrÃ¤sentation

Hier ist eine visuelle Zusammenfassung des Projekts als PrÃ¤sentation:

| Slide | Inhalt                     |
|-------|----------------------------|
| 1     | ProjektÃ¼bersicht           |
| 2     | Methodik & Technik         |
| 3     | Trainingsparameter         |
| 4     | Beispielausgabe: Gleiches Tier |
| 5     | Beispielausgabe: Verschiedenes Tier |

<p align="center">
  <img src="presentation/slide1_overview.png" width="1200"><br>
  <img src="presentation/slide2_method.png" width="1200"><br>
  <img src="presentation/slide3_training.png" width="1200"><br>
  <img src="presentation/slide4_same.png" width="1200"><br>
  <img src="presentation/slide5_diff.png" width="1200">
</p>